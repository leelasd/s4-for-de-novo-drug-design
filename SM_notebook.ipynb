{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/ldodda/Library/Application Support/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.223.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import boto3\n",
    "import sagemaker\n",
    "from time import gmtime, strftime, sleep\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput, \n",
    "    ProcessingOutput, \n",
    "    ScriptProcessor,\n",
    "    FrameworkProcessor\n",
    ")\n",
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep, \n",
    "    TuningStep,\n",
    "    TrainingStep, \n",
    "    CreateModelStep\n",
    ")\n",
    "from sagemaker.workflow.check_job_config import CheckJobConfig\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger, \n",
    "    ParameterFloat, \n",
    "    ParameterString, \n",
    "    ParameterBoolean\n",
    ")\n",
    "from sagemaker.workflow.clarify_check_step import (\n",
    "    ModelBiasCheckConfig, \n",
    "    ClarifyCheckStep, \n",
    "    ModelExplainabilityCheckConfig\n",
    ")\n",
    "from sagemaker import Model\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.conditions import (\n",
    "    ConditionGreaterThan,\n",
    "    ConditionLessThan,\n",
    "    ConditionGreaterThanOrEqualTo\n",
    ")\n",
    "from sagemaker.workflow.pipeline_experiment_config import PipelineExperimentConfig\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import (\n",
    "    Join,\n",
    "    JsonGet\n",
    ")\n",
    "\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "\n",
    "from sagemaker.model_metrics import (\n",
    "    MetricsSource, \n",
    "    ModelMetrics, \n",
    "    FileSource\n",
    ")\n",
    "from sagemaker.drift_check_baselines import DriftCheckBaselines\n",
    "\n",
    "from sagemaker.image_uris import retrieve\n",
    "iam = boto3.client('iam')\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.tokens:Loading cached SSO token for discovery_account\n"
     ]
    }
   ],
   "source": [
    "sm_role = iam.get_role(RoleName='AmazonSageMaker-ExecutionRole-20211206T145568')['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!aws s3 cp ./datasets s3://nimbustx-sagemaker/denovo_design/s4dd/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/pretraining.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/pretraining.py\n",
    "from s4dd import S4forDenovoDesign\n",
    "from argparse import ArgumentParser\n",
    "import os\n",
    "if __name__ == \"__main__\":\n",
    "    parser = ArgumentParser('(Multitask) Regression')\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ[\"SM_MODEL_DIR\"])\n",
    "    #parser.add_argument(\"--full-data\", type=str, default=os.environ[\"SM_CHANNEL_DATA_FULL\"])\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ[\"SM_CHANNEL_TRAIN\"])\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ[\"SM_CHANNEL_TEST\"])\n",
    "    args = parser.parse_args().__dict__\n",
    "\n",
    "    # Create an S4 model\n",
    "    s4 = S4forDenovoDesign(\n",
    "        n_max_epochs=400,  # This is for only demonstration purposes. Set this to a (much) higher value for actual training. Default: 400\n",
    "        batch_size=2048,  # This is for only demonstration purposes. The value in the paper is 2048.\n",
    "        device=\"cuda\",  # replace this with \"cpu\" if you don't have a CUDA-enabled GPU\n",
    "    )\n",
    "    # Pretrain the model on a small subset of ChEMBL\n",
    "    s4.train(\n",
    "        training_molecules_path=f\"{args['train']}/train.zip\",\n",
    "        val_molecules_path=f\"{args['test']}/valid.zip\",\n",
    "    )\n",
    "    # Save the model\n",
    "    s4.save(args['model_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/all_together.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/all_together.py\n",
    "from s4dd import S4forDenovoDesign\n",
    "from argparse import ArgumentParser\n",
    "import os\n",
    "if __name__ == \"__main__\":\n",
    "    parser = ArgumentParser('(Multitask) Regression')\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ[\"SM_MODEL_DIR\"])\n",
    "    #parser.add_argument(\"--full-data\", type=str, default=os.environ[\"SM_CHANNEL_DATA_FULL\"])\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ[\"SM_CHANNEL_TRAIN\"])\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ[\"SM_CHANNEL_TEST\"])\n",
    "    parser.add_argument(\"--output\",type=str, default=os.environ[\"SM_OUTPUT_DATA_DIR\"])\n",
    "    args = parser.parse_args().__dict__\n",
    "\n",
    "    # Create an S4 model with (almost) the same parameters as in the paper.\n",
    "    s4 = S4forDenovoDesign(\n",
    "        n_max_epochs=400,  # This is for only demonstration purposes. Set this to a (much) higher value for actual training. Default: 400.\n",
    "        batch_size=2048,  # This is for only demonstration purposes. The value in the paper is 2048.\n",
    "        device=\"cuda\",  # replace this with \"cpu\" if you don't have a CUDA-enabled GPU.\n",
    "    )\n",
    "    # Pretrain the model on a small subset of ChEMBL\n",
    "    s4.train(\n",
    "        training_molecules_path=f\"{args['train']}/chemblv31/train.zip\",\n",
    "        val_molecules_path=f\"{args['test']}/chemblv31/valid.zip\",\n",
    "    )\n",
    "\n",
    "    # save the pretrained model\n",
    "    s4.save(f\"{args['model_dir']}\")\n",
    "\n",
    "    # Fine-tune the model on a small subset of bioactive molecules\n",
    "    s4.train(\n",
    "        training_molecules_path=f\"{args['train']}/pkm2/train.zip\",\n",
    "        val_molecules_path=f\"{args['train']}/pkm2/valid.zip\",\n",
    "    )\n",
    "\n",
    "    # save the fine-tuned model\n",
    "    s4.save(f\"{args['model_dir']}\")\n",
    "\n",
    "\n",
    "    # Design new molecules\n",
    "    designs, lls = s4.design_molecules(n_designs=128, batch_size=64, temperature=1)\n",
    "\n",
    "    # Save the designs\n",
    "    with open(f\"{args.output}/designs.smiles\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(designs))\n",
    "\n",
    "    # Save the log-likelihoods of the designs\n",
    "    with open(f\"{args.output}/lls.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join([str(ll) for ll in lls]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_estimator = PyTorch(\n",
    "        entry_point='pretraining.py',\n",
    "        source_dir=\"scripts\",\n",
    "        role=sm_role,\n",
    "        framework_version='1.13.1',\n",
    "        instance_count=1,\n",
    "        instance_type='ml.g4dn.2xlarge',\n",
    "        py_version='py39',\n",
    "        max_run=432000,\n",
    "        wait=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_estimator = PyTorch(\n",
    "        entry_point='all_together.py',\n",
    "        source_dir=\"scripts\",\n",
    "        role=sm_role,\n",
    "        framework_version='1.13.1',\n",
    "        instance_count=1,\n",
    "        instance_type='ml.g4dn.2xlarge',\n",
    "        py_version='py39',\n",
    "        max_run=432000,\n",
    "        wait=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2024-08-27-20-45-15-013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-27 20:45:16 Starting - Starting the training job...\n",
      "2024-08-27 20:45:32 Starting - Preparing the instances for training...\n",
      "2024-08-27 20:45:59 Downloading - Downloading input data...\n",
      "2024-08-27 20:46:20 Downloading - Downloading the training image.........."
     ]
    }
   ],
   "source": [
    "train_estimator.fit({'train': 's3://nimbustx-sagemaker/denovo_design/s4dd/chemblv31/', \n",
    "                     'test': 's3://nimbustx-sagemaker/denovo_design/s4dd/chemblv31/'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_estimator.fit({'train': 's3://nimbustx-sagemaker/denovo_design/s4dd/',\n",
    "                     'test': 's3://nimbustx-sagemaker/denovo_design/s4dd/'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
